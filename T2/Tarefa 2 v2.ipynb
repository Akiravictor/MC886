{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression and Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial setup for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup code for this notebook\n",
    "import random \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This is a bit of magic gto make matplotlib figures appear inline\n",
    "# in the notebook rather than in a new window\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using the cifar-10 dataset for Python\n",
    "\n",
    "The following function loads the data inside each batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import _pickle as pickle\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def load_CIFAR_batch(filename):\n",
    "  \"\"\" load single batch of cifar \"\"\"\n",
    "  with open(filename, 'rb') as f:\n",
    "    datadict = pickle.load(f, encoding=\"latin1\")\n",
    "    X = datadict['data']\n",
    "    Y = datadict['labels']\n",
    "    X = X.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"float\")\n",
    "    Y = np.array(Y)\n",
    "    return X, Y\n",
    "\n",
    "def load_CIFAR10(ROOT):\n",
    "  \"\"\" load all of cifar \"\"\"\n",
    "  xs = []\n",
    "  ys = []\n",
    "  for b in range(1,6):\n",
    "    f = os.path.join(ROOT, 'data_batch_%d' % (b, ))\n",
    "    X, Y = load_CIFAR_batch(f)\n",
    "    xs.append(X)\n",
    "    ys.append(Y)    \n",
    "  Xtr = np.concatenate(xs)\n",
    "  Ytr = np.concatenate(ys)\n",
    "  del X, Y\n",
    "  Xte, Yte = load_CIFAR_batch(os.path.join(ROOT, 'test_batch'))\n",
    "  return Xtr, Ytr, Xte, Yte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (3073, 49000)\n",
      "Train labels shape:  (49000,)\n",
      "Validation data shape:  (3073, 1000)\n",
      "Validation labels shape:  (1000,)\n",
      "Test data shape:  (3073, 10000)\n",
      "Test labels shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "def get_CIFAR10_data(num_training=49000, num_val=1000, num_test=10000, show_sample=True):\n",
    "    \"\"\"\n",
    "    Load the CIFAR-10 dataset, and divide the sample into training set, validation set and test set\n",
    "    \"\"\"\n",
    "\n",
    "    cifar10_dir = '../T2/cifar/'\n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "        \n",
    "    # subsample the data for validation set\n",
    "    mask = range(num_training, num_training + num_val)\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = range(num_training)\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = range(num_test)\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "def visualize_sample(X_train, y_train, classes, samples_per_class=7):\n",
    "    \"\"\"visualize some samples in the training datasets \"\"\"\n",
    "    num_classes = len(classes)\n",
    "    for y, cls in enumerate(classes):\n",
    "        idxs = np.flatnonzero(y_train == y) # get all the indexes of cls\n",
    "        idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
    "        for i, idx in enumerate(idxs): # plot the image one by one\n",
    "            plt_idx = i * num_classes + y + 1 # i*num_classes and y+1 determine the row and column respectively\n",
    "            plt.subplot(samples_per_class, num_classes, plt_idx)\n",
    "            plt.imshow(X_train[idx].astype('uint8'))\n",
    "            plt.axis('off')\n",
    "            if i == 0:\n",
    "                plt.title(cls)\n",
    "    plt.show()\n",
    "    \n",
    "def preprocessing_CIFAR10_data(X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    \n",
    "    # Preprocessing: reshape the image data into rows\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], -1)) # [49000, 3072]\n",
    "    X_val = np.reshape(X_val, (X_val.shape[0], -1)) # [1000, 3072]\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], -1)) # [10000, 3072]\n",
    "    \n",
    "    # Normalize the data: subtract the mean image\n",
    "    mean_image = np.mean(X_train, axis = 0)\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_test -= mean_image\n",
    "    \n",
    "    # Add bias dimension and transform into columns\n",
    "    X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))]).T\n",
    "    X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))]).T\n",
    "    X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))]).T\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "\n",
    "# Invoke the above functions to get our data\n",
    "X_train_raw, y_train_raw, X_val_raw, y_val_raw, X_test_raw, y_test_raw = get_CIFAR10_data()\n",
    "#visualize_sample(X_train_raw, y_train_raw, classes)\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = preprocessing_CIFAR10_data(X_train_raw, y_train_raw, X_val_raw, y_val_raw, X_test_raw, y_test_raw)\n",
    "\n",
    "# As a sanity check, we print out th size of the training and test data dimenstion\n",
    "print ('Train data shape: ', X_train.shape)\n",
    "print ('Train labels shape: ', y_train.shape)\n",
    "print ('Validation data shape: ', X_val.shape)\n",
    "print ('Validation labels shape: ', y_val.shape)\n",
    "print ('Test data shape: ', X_test.shape)\n",
    "print ('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the function to apply logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_grad_logistic_naive(W, X, y, reg):\n",
    "    \"\"\"\n",
    "    Compute the loss and gradients using logistic function \n",
    "    with loop, which is slow.\n",
    "    Parameters\n",
    "    ----------\n",
    "    W: (1, D) array of weights, D is the dimension of one sample.\n",
    "    X: (D, N) array of training data, each column is a training sample with D-dimension.\n",
    "    y: (N, ) 1-dimension array of target data with length N.\n",
    "    reg: (float) regularization strength for optimization.\n",
    "    Returns\n",
    "    -------\n",
    "    a tuple of two items (loss, grad)\n",
    "    loss: (float)\n",
    "    grad: (array) with respect to self.W\n",
    "    \"\"\"\n",
    "    dim, num_train = X.shape\n",
    "    loss = 0\n",
    "    grad = np.zeros_like(W) # [1, D]\n",
    "    for i in range(num_train):\n",
    "        sample_x = X[:, i]\n",
    "        f_x = 0\n",
    "        for idx in range(sample_x.shape[0]):\n",
    "            f_x += W[0, idx] * sample_x[idx]\n",
    "        h_x = 1.0 / (1 + np.exp(-f_x))\n",
    "        loss += y[i] * np.log(h_x) + (1 - y[i]) * np.log(1 - h_x)\n",
    "\n",
    "        grad += (h_x - y[i]) * sample_x # [D, ]\n",
    "    loss /= -num_train\n",
    "    loss += 0.5 * reg * np.sum(W * W) # add regularization\n",
    "\n",
    "    grad /= num_train\n",
    "    grad += reg * W # add regularization\n",
    "    return loss, grad\n",
    "\n",
    "def loss_grad_logistic_vectorized(W, X, y, reg):\n",
    "    \"\"\"Compute the loss and gradients with weights, vectorized version\"\"\"\n",
    "    dim, num_train = X.shape\n",
    "    loss = 0\n",
    "    grad = np.zeros_like(W) # [1, D]\n",
    "    # print W\n",
    "    f_x_mat = W.dot(X) # [1, D] * [D, N]\n",
    "    h_x_mat = 1.0 / (1.0 + np.exp(-f_x_mat)) # [1, N]\n",
    "    loss = np.sum(y * np.log(h_x_mat) + (1 - y) * np.log(1 - h_x_mat))\n",
    "    loss = -1.0 / num_train * loss + 0.5 * reg * np.sum(W * W)\n",
    "    grad = (h_x_mat - y).dot(X.T) # [1, D]\n",
    "    grad = 1.0 / num_train * grad + reg * W\n",
    "    \n",
    "    return loss, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: numpy boolean negative, the `-` operator, is deprecated, use the `~` operator or the logical_not function instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive loss: 1.385601, and gradient: computed in 61.110490s\n",
      "Vectorized loss: 1.385601, and gradient: computed in 0.165448s\n",
      "[2693 2307 1753 1704 1864   87  452 2826  667 1229]\n",
      "[  1.25106992   3.80055876  -2.55370414   1.51396641  -4.85823422\n",
      "  10.0128126    2.74323992   3.19256856   7.42340688  -0.92320913]\n",
      "[  1.25106992   3.80055876  -2.55370414   1.51396641  -4.85823422\n",
      "  10.0128126    2.74323992   3.19256856   7.42340688  -0.92320913]\n",
      "Gradient difference between naive and vectorized version is: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Set the label of the first class to be one, and 0 for others\n",
    "from copy import deepcopy\n",
    "y_train_test_loss = deepcopy(y_train)\n",
    "idxs_zero = y_train_test_loss == 0\n",
    "y_train_test_loss[idxs_zero] = 1\n",
    "y_train_test_loss[-idxs_zero] = 0\n",
    "\n",
    "# Test the loss and gradient and compare between two implementations\n",
    "import time\n",
    "\n",
    "# generate a rand weights W \n",
    "W = np.random.randn(1, X_train.shape[0]) * 0.001\n",
    "tic = time.time()\n",
    "loss_naive, grad_naive = loss_grad_logistic_naive(W, X_train, y_train_test_loss, 0)\n",
    "toc = time.time()\n",
    "print (\"Naive loss: %f, and gradient: computed in %fs\" % (loss_naive, toc - tic))\n",
    "\n",
    "tic = time.time()\n",
    "loss_vec, grad_vect = loss_grad_logistic_vectorized(W, X_train, y_train_test_loss, 0)\n",
    "toc = time.time()\n",
    "print (\"Vectorized loss: %f, and gradient: computed in %fs\" % (loss_vec, toc - tic))\n",
    "\n",
    "# Compare the gradient, because the gradient is a vector, we canuse the Frobenius norm to compare them\n",
    "# the Frobenius norm of two matrices is the square root of the squared sum of differences of all elements\n",
    "diff = np.linalg.norm(grad_naive - grad_vect, ord='fro')\n",
    "# Randomly choose some gradient to check\n",
    "idxs = np.random.choice(X_train.shape[0], 10, replace=False)\n",
    "print (idxs)\n",
    "print (grad_naive[0, idxs])\n",
    "print (grad_vect[0, idxs])\n",
    "print (\"Gradient difference between naive and vectorized version is: %f\" % diff)\n",
    "del loss_naive, loss_vec, grad_naive, y_train_test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3073)\n",
      "(0, 1008)\n",
      "numerical: -1.373122 analytic: 6.917547, relative error: 1.000000e+00\n",
      "(0, 1351)\n",
      "numerical: 14.747438 analytic: 4.489653, relative error: 5.332295e-01\n",
      "(0, 899)\n",
      "numerical: 7.869460 analytic: 1.215485, relative error: 7.324178e-01\n",
      "(0, 2919)\n",
      "numerical: 16.769186 analytic: 3.765243, relative error: 6.332751e-01\n",
      "(0, 2279)\n",
      "numerical: 19.911130 analytic: -1.661651, relative error: 1.000000e+00\n",
      "(0, 380)\n",
      "numerical: -5.634660 analytic: 4.624132, relative error: 1.000000e+00\n",
      "(0, 637)\n",
      "numerical: 4.706409 analytic: 4.423459, relative error: 3.099168e-02\n",
      "(0, 755)\n",
      "numerical: 3.979925 analytic: 2.814849, relative error: 1.714665e-01\n",
      "(0, 1034)\n",
      "numerical: 8.815611 analytic: -0.272388, relative error: 1.000000e+00\n",
      "(0, 776)\n",
      "numerical: 8.367582 analytic: 6.155220, relative error: 1.523371e-01\n"
     ]
    }
   ],
   "source": [
    "# file: algorithms/gradient_check.py\n",
    "def grad_check_sparse(f, x, analytic_grad, num_checks):\n",
    "  \"\"\"\n",
    "  sample a few random elements and only return numerical\n",
    "  in this dimensions.\n",
    "  \"\"\"\n",
    "  h = 1e-5\n",
    "\n",
    "  print (x.shape)\n",
    "\n",
    "  for i in range(num_checks):\n",
    "    ix = tuple([random.randrange(m) for m in x.shape])\n",
    "    print (ix)\n",
    "    x[ix] += h # increment by h\n",
    "    fxph = f(x) # evaluate f(x + h)\n",
    "    x[ix] -= 2 * h # increment by h\n",
    "    fxmh = f(x) # evaluate f(x - h)\n",
    "    x[ix] += h # reset\n",
    "\n",
    "    grad_numerical = (fxph - fxmh) / (2 * h)\n",
    "    grad_analytic = analytic_grad[ix]\n",
    "    rel_error = abs(grad_numerical - grad_analytic) / (abs(grad_numerical) + abs(grad_analytic))\n",
    "    print (\"numerical: %f analytic: %f, relative error: %e\" % (grad_numerical, grad_analytic, rel_error))\n",
    "    \n",
    "# Check gradient using numerical gradient along several randomly chosen dimenstion\n",
    "\n",
    "f = lambda w: loss_grad_logistic_vectorized(w, X_train, y_train, 0)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad_vect, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LinearClassifier:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.W = None # set up the weight matrix \n",
    "\n",
    "    def train(self, X, y, method='sgd', batch_size=200, learning_rate=1e-4,\n",
    "              reg = 1e3, num_iters=1000, verbose=False, vectorized=True):\n",
    "        \"\"\"\n",
    "        Train linear classifer using batch gradient descent or stochastic gradient descent\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: (D x N) array of training data, each column is a training sample with D-dimension.\n",
    "        y: (N, ) 1-dimension array of target data with length N.\n",
    "        method: (string) determine whether using 'bgd' or 'sgd'.\n",
    "        batch_size: (integer) number of training examples to use at each step.\n",
    "        learning_rate: (float) learning rate for optimization.\n",
    "        reg: (float) regularization strength for optimization.\n",
    "        num_iters: (integer) number of steps to take when optimization.\n",
    "        verbose: (boolean) if True, print out the progress (loss) when optimization.\n",
    "        Returns\n",
    "        -------\n",
    "        losses_history: (list) of losses at each training iteration\n",
    "        \"\"\"\n",
    "\n",
    "        dim, num_train = X.shape\n",
    "        num_classes = np.max(y) + 1 # assume y takes values 0...K-1 where K is number of classes\n",
    "\n",
    "        if self.W is None:\n",
    "            # initialize the weights with small values\n",
    "            if num_classes == 2: # just need weights for one class\n",
    "                self.W = np.random.randn(1, dim) * 0.001\n",
    "            else: # weigths for each class\n",
    "                self.W = np.random.randn(num_classes, dim) * 0.001\n",
    "\n",
    "        losses_history = []\n",
    "\n",
    "        for i in range(num_iters):\n",
    "            if method == 'bgd':\n",
    "                loss, grad = self.loss_grad(X, y, reg, vectorized)\n",
    "            else:\n",
    "                # randomly choose a min-batch of samples\n",
    "                idxs = np.random.choice(num_train, batch_size, replace=False)\n",
    "                loss, grad = self.loss_grad(X[:, idxs], y[idxs], reg, vectorized) # grad => [K x D]\n",
    "            losses_history.append(loss)\n",
    "\n",
    "            # update weights\n",
    "            self.W -= learning_rate * grad # [K x D]\n",
    "            # print self.W\n",
    "            # print 'dsfad', grad.shape\n",
    "            if verbose and (i % 100 == 0):\n",
    "                print (\"iteration %d/%d: loss %f\" % (i, num_iters, loss))\n",
    "\n",
    "        return losses_history\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict value of y using trained weights\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: (D x N) array of data, each column is a sample with D-dimension.\n",
    "        Returns\n",
    "        -------\n",
    "        pred_ys: (N, ) 1-dimension array of y for N sampels\n",
    "        h_x_mat: Normalized scores\n",
    "        \"\"\"\n",
    "        pred_ys = np.zeros(X.shape[1])\n",
    "        f_x_mat = self.W.dot(X)\n",
    "        if self.__class__.__name__ == 'Logistic':\n",
    "            pred_ys = f_x_mat.squeeze() >=0\n",
    "        else: # multiclassification\n",
    "            pred_ys = np.argmax(f_x_mat, axis=0)\n",
    "        # normalized score\n",
    "        h_x_mat = 1.0 / (1.0 + np.exp(-f_x_mat)) # [1, N]\n",
    "        h_x_mat = h_x_mat.squeeze()\n",
    "        return pred_ys, h_x_mat\n",
    "\n",
    "    def loss_grad(self, X, y, reg, vectorized=True):\n",
    "        \"\"\"\n",
    "        Compute the loss and gradients.\n",
    "        Parameters\n",
    "        ----------\n",
    "        The same as self.train()\n",
    "        Returns\n",
    "        -------\n",
    "        a tuple of two items (loss, grad)\n",
    "        loss: (float)\n",
    "        grad: (array) with respect to self.W\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "# Subclasses of linear classifier\n",
    "class Logistic(LinearClassifier):\n",
    "    \"\"\"A subclass for binary classification using logistic function\"\"\"\n",
    "    def loss_grad(self, X, y, reg, vectorized=True):\n",
    "        if vectorized:\n",
    "            return loss_grad_logistic_vectorized(self.W, X, y, reg)\n",
    "        else:\n",
    "            return loss_grad_logistic_naive(self.W, X, y, reg)\n",
    "\n",
    "\n",
    "class Softmax(LinearClassifier):\n",
    "    \"\"\"A subclass for multi-classicication using Softmax function\"\"\"\n",
    "    def loss_grad(self, X, y, reg, vectorized=True):\n",
    "        if vectorized:\n",
    "            return loss_grad_softmax_vectorized(self.W, X, y, reg)\n",
    "        else:\n",
    "            return loss_grad_softmax_naive(self.W, X, y, reg)\n",
    "\n",
    "\n",
    "class SVM(LinearClassifier):\n",
    "    \"\"\"A subclass for multi-classicication using SVM function\"\"\"\n",
    "    def loss_grad(self, X, y, reg, vectorized=True):\n",
    "        return loss_grad_svm_vectorized(self.W, X, y, reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The 1/10th logistic classifier training...\n",
      "iteration 0/1000: loss 2.698755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: numpy boolean negative, the `-` operator, is deprecated, use the `~` operator or the logical_not function instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 100/1000: loss 2.065364\n",
      "iteration 200/1000: loss 1.741361\n",
      "iteration 300/1000: loss 1.529838\n",
      "iteration 400/1000: loss 1.316915\n",
      "iteration 500/1000: loss 1.205001\n",
      "iteration 600/1000: loss 1.149513\n",
      "iteration 700/1000: loss 0.988679\n",
      "iteration 800/1000: loss 0.964064\n",
      "iteration 900/1000: loss 0.906054\n",
      "\n",
      "The 2/10th logistic classifier training...\n",
      "iteration 0/1000: loss 2.882417\n",
      "iteration 100/1000: loss 1.982794\n",
      "iteration 200/1000: loss 1.756199\n",
      "iteration 300/1000: loss 1.561229\n",
      "iteration 400/1000: loss 1.400618\n",
      "iteration 500/1000: loss 1.214982\n",
      "iteration 600/1000: loss 1.132236\n",
      "iteration 700/1000: loss 1.023040\n",
      "iteration 800/1000: loss 0.947547\n",
      "iteration 900/1000: loss 0.904932\n",
      "\n",
      "The 3/10th logistic classifier training...\n",
      "iteration 0/1000: loss 3.017153\n",
      "iteration 100/1000: loss 2.084206\n",
      "iteration 200/1000: loss 1.793964\n",
      "iteration 300/1000: loss 1.504417\n",
      "iteration 400/1000: loss 1.370568\n",
      "iteration 500/1000: loss 1.221945\n",
      "iteration 600/1000: loss 1.117426\n",
      "iteration 700/1000: loss 1.064424\n",
      "iteration 800/1000: loss 1.003728\n",
      "iteration 900/1000: loss 0.895787\n",
      "\n",
      "The 4/10th logistic classifier training...\n",
      "iteration 0/1000: loss 3.634722\n",
      "iteration 100/1000: loss 2.059598\n",
      "iteration 200/1000: loss 1.777558\n",
      "iteration 300/1000: loss 1.537663\n",
      "iteration 400/1000: loss 1.363406\n",
      "iteration 500/1000: loss 1.282934\n",
      "iteration 600/1000: loss 1.157064\n",
      "iteration 700/1000: loss 1.025349\n",
      "iteration 800/1000: loss 0.960231\n",
      "iteration 900/1000: loss 0.941397\n",
      "\n",
      "The 5/10th logistic classifier training...\n",
      "iteration 0/1000: loss 2.992474\n",
      "iteration 100/1000: loss 2.140491\n",
      "iteration 200/1000: loss 1.736302\n",
      "iteration 300/1000: loss 1.504079\n",
      "iteration 400/1000: loss 1.341285\n",
      "iteration 500/1000: loss 1.216304\n",
      "iteration 600/1000: loss 1.102564\n",
      "iteration 700/1000: loss 1.037837\n",
      "iteration 800/1000: loss 0.979154\n",
      "iteration 900/1000: loss 0.941516\n",
      "\n",
      "The 6/10th logistic classifier training...\n",
      "iteration 0/1000: loss 3.262522\n",
      "iteration 100/1000: loss 2.026330\n",
      "iteration 200/1000: loss 1.784590\n",
      "iteration 300/1000: loss 1.534054\n",
      "iteration 400/1000: loss 1.333121\n",
      "iteration 500/1000: loss 1.199697\n",
      "iteration 600/1000: loss 1.109428\n",
      "iteration 700/1000: loss 1.016417\n",
      "iteration 800/1000: loss 0.970791\n",
      "iteration 900/1000: loss 0.862905\n",
      "\n",
      "The 7/10th logistic classifier training...\n",
      "iteration 0/1000: loss 2.816580\n",
      "iteration 100/1000: loss 1.988411\n",
      "iteration 200/1000: loss 1.789769\n",
      "iteration 300/1000: loss 1.486896\n",
      "iteration 400/1000: loss 1.351448\n",
      "iteration 500/1000: loss 1.212700\n",
      "iteration 600/1000: loss 1.143521\n",
      "iteration 700/1000: loss 1.063447\n",
      "iteration 800/1000: loss 0.940611\n",
      "iteration 900/1000: loss 0.869632\n",
      "\n",
      "The 8/10th logistic classifier training...\n",
      "iteration 0/1000: loss 2.919930\n",
      "iteration 100/1000: loss 2.151702\n",
      "iteration 200/1000: loss 1.739489\n",
      "iteration 300/1000: loss 1.511868\n",
      "iteration 400/1000: loss 1.373872\n",
      "iteration 500/1000: loss 1.236491\n",
      "iteration 600/1000: loss 1.167593\n",
      "iteration 700/1000: loss 1.015354\n",
      "iteration 800/1000: loss 0.966325\n",
      "iteration 900/1000: loss 0.829157\n",
      "\n",
      "The 9/10th logistic classifier training...\n",
      "iteration 0/1000: loss 2.946352\n",
      "iteration 100/1000: loss 2.079181\n",
      "iteration 200/1000: loss 1.744021\n",
      "iteration 300/1000: loss 1.472661\n",
      "iteration 400/1000: loss 1.388145\n",
      "iteration 500/1000: loss 1.204407\n",
      "iteration 600/1000: loss 1.130114\n",
      "iteration 700/1000: loss 1.028256\n",
      "iteration 800/1000: loss 0.987687\n",
      "iteration 900/1000: loss 0.921416\n",
      "\n",
      "The 10/10th logistic classifier training...\n",
      "iteration 0/1000: loss 2.766574\n",
      "iteration 100/1000: loss 2.081441\n",
      "iteration 200/1000: loss 1.768958\n",
      "iteration 300/1000: loss 1.532193\n",
      "iteration 400/1000: loss 1.349276\n",
      "iteration 500/1000: loss 1.239272\n",
      "iteration 600/1000: loss 1.149492\n",
      "iteration 700/1000: loss 1.044506\n",
      "iteration 800/1000: loss 0.969804\n",
      "iteration 900/1000: loss 0.910452\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logistic_classifiers = []\n",
    "num_classes = np.max(y_train) + 1\n",
    "losses = []\n",
    "for i in range(num_classes):\n",
    "    print (\"\\nThe %d/%dth logistic classifier training...\" % (i+1, num_classes))\n",
    "    y_train_logistic = deepcopy(y_train)\n",
    "    idxs_i = y_train_logistic == i\n",
    "    y_train_logistic[idxs_i] = 1\n",
    "    y_train_logistic[-idxs_i] = 0\n",
    "    logistic = Logistic()\n",
    "    loss = logistic.train(X_train, y_train_logistic, method='sgd', batch_size=200, learning_rate=1e-6,\n",
    "              reg = 1e3, num_iters=1000, verbose=True, vectorized=True)\n",
    "    losses.append(loss)\n",
    "    logistic_classifiers.append(logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ggplot\\utils.py:81: FutureWarning: pandas.tslib is deprecated and will be removed in a future version.\n",
      "You can access Timestamp as pandas.Timestamp\n",
      "  pd.tslib.Timestamp,\n",
      "D:\\Anaconda3\\lib\\site-packages\\ggplot\\stats\\smoothers.py:4: FutureWarning: The pandas.lib module is deprecated and will be removed in a future version. These are private functions and can be accessed from pandas._libs.lib instead\n",
      "  from pandas.lib import Timestamp\n",
      "D:\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuEAAAHvCAYAAAD6ogF/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1de54f2ecc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<ggplot: (-9223371908453552503)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ggplot import *\n",
    "# plot the loss of the last trained logistic classifier\n",
    "qplot(range(len(losses[9])), losses[9]) + labs(x='Iteration number', y='SGD Loss for last trained classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset accuracy: 0.338224\n",
      "Validation dataset accuracy: 0.351000\n",
      "Test datast accuracy: 0.331100\n"
     ]
    }
   ],
   "source": [
    "# Compute the accuracy of training data and validation data\n",
    "def predict_one_vs_all(logistic_classifiers, X, num_classes):\n",
    "    scores = np.zeros((num_classes, X.shape[1]))\n",
    "    for i in range(num_classes):\n",
    "        logistic = logistic_classifiers[i]\n",
    "        scores[i, :] = logistic.predict(X)[1]\n",
    "    pred_X = np.argmax(scores, axis=0)\n",
    "    return pred_X\n",
    "\n",
    "pred_train_one_vs_all = predict_one_vs_all(logistic_classifiers, X_train, num_classes)\n",
    "pred_val_one_vs_all = predict_one_vs_all(logistic_classifiers, X_val, num_classes)\n",
    "pred_test_one_vs_all = predict_one_vs_all(logistic_classifiers, X_test, num_classes)\n",
    "print (\"Training dataset accuracy: %f\" % (np.mean(y_train == pred_train_one_vs_all)))\n",
    "print (\"Validation dataset accuracy: %f\" % (np.mean(y_val == pred_val_one_vs_all)))\n",
    "print (\"Test datast accuracy: %f\" % (np.mean(y_test == pred_test_one_vs_all)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# file: algorithms/classifiers/loss_grad_softmax.py\n",
    "import numpy as np\n",
    "\n",
    "def loss_grad_softmax_naive(W, X, y, reg):\n",
    "    \"\"\"\n",
    "    Compute the loss and gradients using softmax function \n",
    "    with loop, which is slow.\n",
    "    Parameters\n",
    "    ----------\n",
    "    W: (K, D) array of weights, K is the number of classes and D is the dimension of one sample.\n",
    "    X: (D, N) array of training data, each column is a training sample with D-dimension.\n",
    "    y: (N, ) 1-dimension array of target data with length N with lables 0,1, ... K-1, for K classes\n",
    "    reg: (float) regularization strength for optimization.\n",
    "    Returns\n",
    "    -------\n",
    "    a tuple of two items (loss, grad)\n",
    "    loss: (float)\n",
    "    grad: (K, D) with respect to W\n",
    "    \"\"\"\n",
    "    loss = 0\n",
    "    grad = np.zeros_like(W)\n",
    "    dim, num_train = X.shape\n",
    "    num_classes = W.shape[0]\n",
    "    for i in range(num_train):\n",
    "        sample_x = X[:, i]\n",
    "        scores = np.zeros(num_classes) # [K, 1] unnormalized score\n",
    "        for cls in range(num_classes):\n",
    "            w = W[cls, :]\n",
    "            scores[cls] = w.dot(sample_x)\n",
    "        # Shift the scores so that the highest value is 0\n",
    "        scores -= np.max(scores)\n",
    "        correct_class = y[i]\n",
    "        sum_exp_scores = np.sum(np.exp(scores))\n",
    "\n",
    "        corr_cls_exp_score = np.exp(scores[correct_class])\n",
    "        loss_x = -np.log(corr_cls_exp_score / sum_exp_scores)\n",
    "        loss += loss_x\n",
    "\n",
    "        # compute the gradient\n",
    "        percent_exp_score = np.exp(scores) / sum_exp_scores\n",
    "        for j in range(num_classes):\n",
    "            grad[j, :] += percent_exp_score[j] * sample_x\n",
    "\n",
    "\n",
    "        grad[correct_class, :] -= sample_x # deal with the correct class\n",
    "\n",
    "    loss /= num_train\n",
    "    loss += 0.5 * reg * np.sum(W * W) # add regularization\n",
    "    grad /= num_train\n",
    "    grad += reg * W\n",
    "    return loss, grad\n",
    "\n",
    "def loss_grad_softmax_vectorized(W, X, y, reg):\n",
    "    \"\"\" Compute the loss and gradients using softmax with vectorized version\"\"\"\n",
    "    loss = 0 \n",
    "    grad = np.zeros_like(W)\n",
    "    dim, num_train = X.shape\n",
    "\n",
    "    scores = W.dot(X) # [K, N]\n",
    "    # Shift scores so that the highest value is 0\n",
    "    scores -= np.max(scores)\n",
    "    scores_exp = np.exp(scores)\n",
    "    correct_scores_exp = scores_exp[y, range(num_train)] # [N, ]\n",
    "    scores_exp_sum = np.sum(scores_exp, axis=0) # [N, ]\n",
    "    loss = -np.sum(np.log(correct_scores_exp / scores_exp_sum))\n",
    "    loss /= num_train\n",
    "    loss += 0.5 * reg * np.sum(W * W)\n",
    "\n",
    "    scores_exp_normalized = scores_exp / scores_exp_sum\n",
    "    # deal with the correct class\n",
    "    scores_exp_normalized[y, range(num_train)] -= 1 # [K, N]\n",
    "    grad = scores_exp_normalized.dot(X.T)\n",
    "    grad /= num_train\n",
    "    grad += reg * W\n",
    "\n",
    "    return loss, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive loss: 6.221538, and gradient: computed in 3.899368s\n",
      "Vectorized loss: 6.221538, and gradient: computed in 0.170453s\n",
      "[3020 1027 1874  485  329  558 2369 1042 2098 1672]\n",
      "[-7.33878828 -2.50394184 -4.32875319 -3.64524178 -4.92517243  0.16006863\n",
      " -8.28531784 -1.63295044 -6.45780613 -2.59133083]\n",
      "[-7.33878828 -2.50394184 -4.32875319 -3.64524178 -4.92517243  0.16006863\n",
      " -8.28531784 -1.63295044 -6.45780613 -2.59133083]\n",
      "Gradient difference between naive and vectorized version is: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# generate a rand weights W \n",
    "W = np.random.randn(10, X_train.shape[0]) * 0.001\n",
    "tic = time.time()\n",
    "loss_naive, grad_naive = loss_grad_softmax_naive(W, X_train, y_train, 0.0001)\n",
    "toc = time.time()\n",
    "print (\"Naive loss: %f, and gradient: computed in %fs\" % (loss_naive, toc - tic))\n",
    "\n",
    "tic = time.time()\n",
    "loss_vec, grad_vect = loss_grad_softmax_vectorized(W, X_train, y_train, 0.0001)\n",
    "toc = time.time()\n",
    "print (\"Vectorized loss: %f, and gradient: computed in %fs\" % (loss_vec, toc - tic))\n",
    "\n",
    "# Compare the gradient, because the gradient is a vector, we canuse the Frobenius norm to compare them\n",
    "# the Frobenius norm of two matrices is the square root of the squared sum of differences of all elements\n",
    "diff = np.linalg.norm(grad_naive - grad_vect, ord='fro')\n",
    "# Randomly choose some gradient to check\n",
    "idxs = np.random.choice(X_train.shape[0], 10, replace=False)\n",
    "print (idxs)\n",
    "print (grad_naive[0, idxs])\n",
    "print (grad_vect[0, idxs])\n",
    "print (\"Gradient difference between naive and vectorized version is: %f\" % diff)\n",
    "del loss_naive, loss_vec, grad_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_check_sparse(f, x, analytic_grad, num_checks):\n",
    "  \"\"\"\n",
    "  sample a few random elements and only return numerical\n",
    "  in this dimensions.\n",
    "  \"\"\"\n",
    "  h = 1e-5\n",
    "\n",
    "  print (x.shape)\n",
    "\n",
    "  for i in range(num_checks):\n",
    "    ix = tuple([random.randrange(m) for m in x.shape])\n",
    "    print (ix)\n",
    "    x[ix] += h # increment by h\n",
    "    fxph = f(x) # evaluate f(x + h)\n",
    "    x[ix] -= 2 * h # increment by h\n",
    "    fxmh = f(x) # evaluate f(x - h)\n",
    "    x[ix] += h # reset\n",
    "\n",
    "    grad_numerical = (fxph - fxmh) / (2 * h)\n",
    "    grad_analytic = analytic_grad[ix]\n",
    "    rel_error = abs(grad_numerical - grad_analytic) / (abs(grad_numerical) + abs(grad_analytic))\n",
    "    print (\"numerical: %f analytic: %f, relative error: %e\" % (grad_numerical, grad_analytic, rel_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 3073)\n",
      "(2, 1320)\n",
      "numerical: -0.962993 analytic: -0.962993, relative error: 3.071797e-08\n",
      "(4, 3016)\n",
      "numerical: -0.507678 analytic: -0.507679, relative error: 1.224353e-07\n",
      "(1, 1954)\n",
      "numerical: 3.804140 analytic: 3.804140, relative error: 2.498974e-09\n",
      "(9, 359)\n",
      "numerical: -9.530497 analytic: -9.530497, relative error: 8.034080e-09\n",
      "(7, 329)\n",
      "numerical: -2.749351 analytic: -2.749351, relative error: 3.482173e-09\n",
      "(2, 2369)\n",
      "numerical: 0.612546 analytic: 0.612547, relative error: 1.643499e-07\n",
      "(1, 278)\n",
      "numerical: -3.644120 analytic: -3.644120, relative error: 2.335230e-08\n",
      "(5, 651)\n",
      "numerical: 5.164037 analytic: 5.164037, relative error: 1.294487e-08\n",
      "(4, 2566)\n",
      "numerical: 0.326029 analytic: 0.326029, relative error: 4.608299e-07\n",
      "(1, 865)\n",
      "numerical: -1.069318 analytic: -1.069318, relative error: 5.187793e-08\n"
     ]
    }
   ],
   "source": [
    "# Check gradient using numerical gradient along several randomly chosen dimenstion\n",
    "f = lambda w: loss_grad_softmax_vectorized(w, X_train, y_train, 0)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad_vect, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0/1000: loss 1525.296801\n",
      "iteration 100/1000: loss 2.132342\n",
      "iteration 200/1000: loss 2.167871\n",
      "iteration 300/1000: loss 2.152555\n",
      "iteration 400/1000: loss 2.143142\n",
      "iteration 500/1000: loss 2.211829\n",
      "iteration 600/1000: loss 2.156675\n",
      "iteration 700/1000: loss 2.144379\n",
      "iteration 800/1000: loss 2.148133\n",
      "iteration 900/1000: loss 2.191718\n",
      "Traning time for SGD with vectorized version is 4.315476 \n",
      "\n",
      "Training accuracy: 0.277939\n",
      "Validation accuracy: 0.298000\n"
     ]
    }
   ],
   "source": [
    "# # using BGD algorithm\n",
    "# softmax_bgd = Softmax()\n",
    "# tic = time.time()\n",
    "# losses_bgd = softmax_bgd.train(X_train, y_train, method='bgd', batch_size=200, learning_rate=1e-6,\n",
    "#               reg = 1e2, num_iters=1000, verbose=True, vectorized=True)\n",
    "# toc = time.time()\n",
    "# print 'Traning time for BGD with vectorized version is %f \\n' % (toc - tic)\n",
    "\n",
    "# # Compute the accuracy of training data and validation data using Softmax.predict function\n",
    "# y_train_pred_bgd = softmax_bgd.predict(X_train)[0]\n",
    "# print 'Training accuracy: %f' % (np.mean(y_train == y_train_pred_bgd))\n",
    "# y_val_pred_bgd = softmax_bgd.predict(X_val)[0]\n",
    "# print 'Validation accuracy: %f' % (np.mean(y_val == y_val_pred_bgd))\n",
    "\n",
    "# # using SGD algorithm\n",
    "softmax_sgd = Softmax()\n",
    "tic = time.time()\n",
    "losses_sgd = softmax_sgd.train(X_train, y_train, method='sgd', batch_size=200, learning_rate=1e-6,\n",
    "              reg = 1e5, num_iters=1000, verbose=True, vectorized=True)\n",
    "toc = time.time()\n",
    "print (\"Traning time for SGD with vectorized version is %f \\n\" % (toc - tic))\n",
    "\n",
    "y_train_pred_sgd = softmax_sgd.predict(X_train)[0]\n",
    "print (\"Training accuracy: %f\" % (np.mean(y_train == y_train_pred_sgd)))\n",
    "y_val_pred_sgd = softmax_sgd.predict(X_val)[0]\n",
    "print (\"Validation accuracy: %f\" % (np.mean(y_val == y_val_pred_sgd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuEAAAH0CAYAAACTs/MnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzmHyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1de54ff1978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<ggplot: (-9223371908453502625)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ggplot import *\n",
    "qplot(range(len(losses_sgd)), losses_sgd) + labs(x='Iteration number', y='SGD Loss value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current iteration is 1/5\n",
      "The current iteration is 2/5\n",
      "The current iteration is 3/5\n",
      "The current iteration is 4/5\n",
      "The current iteration is 5/5\n",
      "learning rate 1.000000e-08 and regularization 1.000000e+03, \n",
      "     the training accuracy is: 0.154184 and validation accuracy is: 0.144000.\n",
      "\n",
      "learning rate 1.000000e-08 and regularization 2.575000e+04, \n",
      "     the training accuracy is: 0.135347 and validation accuracy is: 0.134000.\n",
      "\n",
      "learning rate 1.000000e-08 and regularization 5.050000e+04, \n",
      "     the training accuracy is: 0.155245 and validation accuracy is: 0.170000.\n",
      "\n",
      "learning rate 1.000000e-08 and regularization 7.525000e+04, \n",
      "     the training accuracy is: 0.178673 and validation accuracy is: 0.171000.\n",
      "\n",
      "learning rate 1.000000e-08 and regularization 1.000000e+05, \n",
      "     the training accuracy is: 0.148388 and validation accuracy is: 0.137000.\n",
      "\n",
      "learning rate 2.507500e-06 and regularization 1.000000e+03, \n",
      "     the training accuracy is: 0.400735 and validation accuracy is: 0.400000.\n",
      "\n",
      "learning rate 2.507500e-06 and regularization 2.575000e+04, \n",
      "     the training accuracy is: 0.320020 and validation accuracy is: 0.338000.\n",
      "\n",
      "learning rate 2.507500e-06 and regularization 5.050000e+04, \n",
      "     the training accuracy is: 0.293408 and validation accuracy is: 0.297000.\n",
      "\n",
      "learning rate 2.507500e-06 and regularization 7.525000e+04, \n",
      "     the training accuracy is: 0.278755 and validation accuracy is: 0.295000.\n",
      "\n",
      "learning rate 2.507500e-06 and regularization 1.000000e+05, \n",
      "     the training accuracy is: 0.247163 and validation accuracy is: 0.258000.\n",
      "\n",
      "learning rate 5.005000e-06 and regularization 1.000000e+03, \n",
      "     the training accuracy is: 0.376041 and validation accuracy is: 0.377000.\n",
      "\n",
      "learning rate 5.005000e-06 and regularization 2.575000e+04, \n",
      "     the training accuracy is: 0.263939 and validation accuracy is: 0.264000.\n",
      "\n",
      "learning rate 5.005000e-06 and regularization 5.050000e+04, \n",
      "     the training accuracy is: 0.224796 and validation accuracy is: 0.224000.\n",
      "\n",
      "learning rate 5.005000e-06 and regularization 7.525000e+04, \n",
      "     the training accuracy is: 0.145245 and validation accuracy is: 0.127000.\n",
      "\n",
      "learning rate 5.005000e-06 and regularization 1.000000e+05, \n",
      "     the training accuracy is: 0.120714 and validation accuracy is: 0.136000.\n",
      "\n",
      "learning rate 7.502500e-06 and regularization 1.000000e+03, \n",
      "     the training accuracy is: 0.275286 and validation accuracy is: 0.294000.\n",
      "\n",
      "learning rate 7.502500e-06 and regularization 2.575000e+04, \n",
      "     the training accuracy is: 0.159306 and validation accuracy is: 0.159000.\n",
      "\n",
      "learning rate 7.502500e-06 and regularization 5.050000e+04, \n",
      "     the training accuracy is: 0.143061 and validation accuracy is: 0.139000.\n",
      "\n",
      "learning rate 7.502500e-06 and regularization 7.525000e+04, \n",
      "     the training accuracy is: 0.106388 and validation accuracy is: 0.117000.\n",
      "\n",
      "learning rate 7.502500e-06 and regularization 1.000000e+05, \n",
      "     the training accuracy is: 0.111327 and validation accuracy is: 0.095000.\n",
      "\n",
      "learning rate 1.000000e-05 and regularization 1.000000e+03, \n",
      "     the training accuracy is: 0.267082 and validation accuracy is: 0.272000.\n",
      "\n",
      "learning rate 1.000000e-05 and regularization 2.575000e+04, \n",
      "     the training accuracy is: 0.114163 and validation accuracy is: 0.117000.\n",
      "\n",
      "learning rate 1.000000e-05 and regularization 5.050000e+04, \n",
      "     the training accuracy is: 0.125429 and validation accuracy is: 0.141000.\n",
      "\n",
      "learning rate 1.000000e-05 and regularization 7.525000e+04, \n",
      "     the training accuracy is: 0.082286 and validation accuracy is: 0.072000.\n",
      "\n",
      "learning rate 1.000000e-05 and regularization 1.000000e+05, \n",
      "     the training accuracy is: 0.101857 and validation accuracy is: 0.120000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using validation set to tuen hyperparameters, i.e., learning rate and regularization strength\n",
    "learning_rates = [1e-5, 1e-8]\n",
    "regularization_strengths = [10e2, 10e4]\n",
    "\n",
    "# Result is a dictionary mapping tuples of the form (learning_rate, regularization_strength) \n",
    "# to tuples of the form (training_accuracy, validation_accuracy). The accuracy is simply the fraction\n",
    "# of data points that are correctly classified.\n",
    "results = {}\n",
    "best_val = -1\n",
    "best_softmax = None\n",
    "# Choose the best hyperparameters by tuning on the validation set\n",
    "i = 0\n",
    "interval = 5\n",
    "for learning_rate in np.linspace(learning_rates[0], learning_rates[1], num=interval):\n",
    "    i += 1\n",
    "    print (\"The current iteration is %d/%d\" % (i, interval))\n",
    "    for reg in np.linspace(regularization_strengths[0], regularization_strengths[1], num=interval):\n",
    "        softmax = Softmax()\n",
    "        softmax.train(X_train, y_train, method='sgd', batch_size=200, learning_rate=learning_rate,\n",
    "              reg = reg, num_iters=1000, verbose=False, vectorized=True)\n",
    "        y_train_pred = softmax.predict(X_train)[0]\n",
    "        y_val_pred = softmax.predict(X_val)[0]\n",
    "        train_accuracy = np.mean(y_train == y_train_pred)\n",
    "        val_accuracy = np.mean(y_val == y_val_pred)\n",
    "        results[(learning_rate, reg)] = (train_accuracy, val_accuracy)\n",
    "        if val_accuracy > best_val:\n",
    "            best_val = val_accuracy\n",
    "            best_softmax = softmax\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "# Print out the results\n",
    "for learning_rate, reg in sorted(results):\n",
    "    train_accuracy,val_accuracy = results[(learning_rate, reg)]\n",
    "    print (\"learning rate %e and regularization %e, \\n \\\n",
    "    the training accuracy is: %f and validation accuracy is: %f.\\n\" % (learning_rate, reg, train_accuracy, val_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy is: 0.390600\n"
     ]
    }
   ],
   "source": [
    "y_test_predict_result = best_softmax.predict(X_test)\n",
    "y_test_predict = y_test_predict_result[0]\n",
    "test_accuracy = np.mean(y_test == y_test_predict)\n",
    "print (\"The test accuracy is: %f\" % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "def relu(z):\n",
    "    return np.maximum(0, z)\n",
    "def derivative(f, z, eps=0.000001):\n",
    "    return (f(z + eps) - f(z - eps))/(2 * eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a neural network with 1 hidden layer with 2000 neurons\n",
    "\n",
    "Taking 3500 steps to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Akira\\AppData\\Local\\Temp\\tmp5jmjqb78\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001DE682CD7F0>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_tf_random_seed': 42, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': 'C:\\\\Users\\\\Akira\\\\AppData\\\\Local\\\\Temp\\\\tmp5jmjqb78'}\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py:642: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\Akira\\AppData\\Local\\Temp\\tmp5jmjqb78\\model.ckpt.\n",
      "INFO:tensorflow:loss = 165.112, step = 1\n",
      "INFO:tensorflow:global_step/sec: 1.71923\n",
      "INFO:tensorflow:loss = 2.30999, step = 101 (58.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.72464\n",
      "INFO:tensorflow:loss = 2.31238, step = 201 (57.990 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.67807\n",
      "INFO:tensorflow:loss = 2.29744, step = 301 (59.585 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.70661\n",
      "INFO:tensorflow:loss = 2.29828, step = 401 (58.597 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.72652\n",
      "INFO:tensorflow:loss = 2.30056, step = 501 (57.926 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.71606\n",
      "INFO:tensorflow:loss = 2.31154, step = 601 (58.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.69705\n",
      "INFO:tensorflow:loss = 2.29776, step = 701 (58.928 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.68646\n",
      "INFO:tensorflow:loss = 2.29888, step = 801 (59.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.7048\n",
      "INFO:tensorflow:loss = 2.29455, step = 901 (58.651 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.6909\n",
      "INFO:tensorflow:loss = 2.30078, step = 1001 (59.140 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1008 into C:\\Users\\Akira\\AppData\\Local\\Temp\\tmp5jmjqb78\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.43419\n",
      "INFO:tensorflow:loss = 2.29343, step = 1101 (69.727 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.68384\n",
      "INFO:tensorflow:loss = 2.29013, step = 1201 (59.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.71244\n",
      "INFO:tensorflow:loss = 2.30372, step = 1301 (58.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.70898\n",
      "INFO:tensorflow:loss = 2.20875, step = 1401 (58.508 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.68772\n",
      "INFO:tensorflow:loss = 2.30087, step = 1501 (59.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.70915\n",
      "INFO:tensorflow:loss = 2.30124, step = 1601 (58.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.71577\n",
      "INFO:tensorflow:loss = 2.30981, step = 1701 (58.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.70889\n",
      "INFO:tensorflow:loss = 2.30477, step = 1801 (58.518 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.70953\n",
      "INFO:tensorflow:loss = 2.30323, step = 1901 (58.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.71524\n",
      "INFO:tensorflow:loss = 2.29499, step = 2001 (58.295 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2013 into C:\\Users\\Akira\\AppData\\Local\\Temp\\tmp5jmjqb78\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.47082\n",
      "INFO:tensorflow:loss = 2.2486, step = 2101 (67.994 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.73904\n",
      "INFO:tensorflow:loss = 2.30031, step = 2201 (57.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.72464\n",
      "INFO:tensorflow:loss = 2.31029, step = 2301 (57.983 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.70819\n",
      "INFO:tensorflow:loss = 2.30577, step = 2401 (58.549 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.72787\n",
      "INFO:tensorflow:loss = 2.29509, step = 2501 (57.868 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.72261\n",
      "INFO:tensorflow:loss = 2.3032, step = 2601 (58.051 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.72766\n",
      "INFO:tensorflow:loss = 2.30474, step = 2701 (57.883 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.72963\n",
      "INFO:tensorflow:loss = 2.3026, step = 2801 (57.815 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.6974\n",
      "INFO:tensorflow:loss = 2.30453, step = 2901 (58.914 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.72339\n",
      "INFO:tensorflow:loss = 2.29538, step = 3001 (58.032 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3030 into C:\\Users\\Akira\\AppData\\Local\\Temp\\tmp5jmjqb78\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.48956\n",
      "INFO:tensorflow:loss = 2.25572, step = 3101 (67.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.72413\n",
      "INFO:tensorflow:loss = 2.30677, step = 3201 (58.006 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.7279\n",
      "INFO:tensorflow:loss = 2.29485, step = 3301 (57.867 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.71441\n",
      "INFO:tensorflow:loss = 2.298, step = 3401 (58.329 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3500 into C:\\Users\\Akira\\AppData\\Local\\Temp\\tmp5jmjqb78\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2.30254.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SKCompat()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "config = tf.contrib.learn.RunConfig(tf_random_seed=42) # not shown in the config\n",
    "\n",
    "feature_cols = tf.contrib.learn.infer_real_valued_columns_from_input(X_train)\n",
    "dnn_clf = tf.contrib.learn.DNNClassifier(hidden_units=[2000], n_classes=10, feature_columns=feature_cols, config=config)\n",
    "dnn_clf = tf.contrib.learn.SKCompat(dnn_clf) # if TensorFlow >= 1.1\n",
    "dnn_clf.fit(X_train, y_train, batch_size=50, steps=3500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.framework.ops.Tensor'>):\n",
      "<tf.Tensor 'report_uninitialized_variables_1/boolean_mask/Gather:0' shape=(?,) dtype=string>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "['File \"D:\\\\Anaconda3\\\\lib\\\\runpy.py\", line 193, in _run_module_as_main\\n    \"__main__\", mod_spec)', 'File \"D:\\\\Anaconda3\\\\lib\\\\runpy.py\", line 85, in _run_code\\n    exec(code, run_globals)', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py\", line 16, in <module>\\n    app.launch_new_instance()', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\traitlets\\\\config\\\\application.py\", line 658, in launch_instance\\n    app.start()', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py\", line 477, in start\\n    ioloop.IOLoop.instance().start()', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\zmq\\\\eventloop\\\\ioloop.py\", line 177, in start\\n    super(ZMQIOLoop, self).start()', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\tornado\\\\ioloop.py\", line 888, in start\\n    handler_func(fd_obj, events)', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\tornado\\\\stack_context.py\", line 277, in null_wrapper\\n    return fn(*args, **kwargs)', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\zmq\\\\eventloop\\\\zmqstream.py\", line 440, in _handle_events\\n    self._handle_recv()', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\zmq\\\\eventloop\\\\zmqstream.py\", line 472, in _handle_recv\\n    self._run_callback(callback, msg)', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\zmq\\\\eventloop\\\\zmqstream.py\", line 414, in _run_callback\\n    callback(*args, **kwargs)', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\tornado\\\\stack_context.py\", line 277, in null_wrapper\\n    return fn(*args, **kwargs)', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelbase.py\", line 283, in dispatcher\\n    return self.dispatch_shell(stream, msg)', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelbase.py\", line 235, in dispatch_shell\\n    handler(stream, idents, msg)', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelbase.py\", line 399, in execute_request\\n    user_expressions, allow_stdin)', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\ipykernel\\\\ipkernel.py\", line 196, in do_execute\\n    res = shell.run_cell(code, store_history=store_history, silent=silent)', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\ipykernel\\\\zmqshell.py\", line 533, in run_cell\\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\IPython\\\\core\\\\interactiveshell.py\", line 2717, in run_cell\\n    interactivity=interactivity, compiler=compiler, result=result)', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\IPython\\\\core\\\\interactiveshell.py\", line 2821, in run_ast_nodes\\n    if self.run_code(code, result):', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\IPython\\\\core\\\\interactiveshell.py\", line 2881, in run_code\\n    exec(code_obj, self.user_global_ns, self.user_ns)', 'File \"<ipython-input-35-cbbb0c9eab03>\", line 3, in <module>\\n    y_pred = dnn_clf.predict(X_test)', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\tensorflow\\\\contrib\\\\learn\\\\python\\\\learn\\\\estimators\\\\estimator.py\", line 1383, in predict\\n    iterate_batches=True))', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\tensorflow\\\\contrib\\\\learn\\\\python\\\\learn\\\\estimators\\\\estimator.py\", line 893, in _infer_model\\n    config=self._session_config))', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\training\\\\monitored_session.py\", line 668, in __init__\\n    stop_grace_period_secs=stop_grace_period_secs)', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\training\\\\monitored_session.py\", line 490, in __init__\\n    self._sess = _RecoverableSession(self._coordinated_creator)', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\training\\\\monitored_session.py\", line 842, in __init__\\n    _WrappedSession.__init__(self, self._create_session())', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\training\\\\monitored_session.py\", line 847, in _create_session\\n    return self._sess_creator.create_session()', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\training\\\\monitored_session.py\", line 551, in create_session\\n    self.tf_sess = self._session_creator.create_session()', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\training\\\\monitored_session.py\", line 416, in create_session\\n    self._scaffold.finalize()', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\training\\\\monitored_session.py\", line 196, in finalize\\n    default_ready_for_local_init_op)', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\training\\\\monitored_session.py\", line 258, in get_or_default\\n    op = default_constructor()', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\training\\\\monitored_session.py\", line 193, in default_ready_for_local_init_op\\n    variables.global_variables())', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\util\\\\tf_should_use.py\", line 175, in wrapped\\n    return _add_should_use_warning(fn(*args, **kwargs))', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\util\\\\tf_should_use.py\", line 144, in _add_should_use_warning\\n    wrapped = TFShouldUseWarningWrapper(x)', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\util\\\\tf_should_use.py\", line 101, in __init__\\n    stack = [s.strip() for s in traceback.format_stack()]']\n",
      "==================================\n",
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.framework.ops.Tensor'>):\n",
      "<tf.Tensor 'report_uninitialized_variables_1/boolean_mask/Gather:0' shape=(?,) dtype=string>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "['File \"D:\\\\Anaconda3\\\\lib\\\\runpy.py\", line 193, in _run_module_as_main\\n    \"__main__\", mod_spec)', 'File \"D:\\\\Anaconda3\\\\lib\\\\runpy.py\", line 85, in _run_code\\n    exec(code, run_globals)', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py\", line 16, in <module>\\n    app.launch_new_instance()', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\traitlets\\\\config\\\\application.py\", line 658, in launch_instance\\n    app.start()', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py\", line 477, in start\\n    ioloop.IOLoop.instance().start()', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\zmq\\\\eventloop\\\\ioloop.py\", line 177, in start\\n    super(ZMQIOLoop, self).start()', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\tornado\\\\ioloop.py\", line 888, in start\\n    handler_func(fd_obj, events)', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\tornado\\\\stack_context.py\", line 277, in null_wrapper\\n    return fn(*args, **kwargs)', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\zmq\\\\eventloop\\\\zmqstream.py\", line 440, in _handle_events\\n    self._handle_recv()', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\zmq\\\\eventloop\\\\zmqstream.py\", line 472, in _handle_recv\\n    self._run_callback(callback, msg)', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\zmq\\\\eventloop\\\\zmqstream.py\", line 414, in _run_callback\\n    callback(*args, **kwargs)', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\tornado\\\\stack_context.py\", line 277, in null_wrapper\\n    return fn(*args, **kwargs)', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelbase.py\", line 283, in dispatcher\\n    return self.dispatch_shell(stream, msg)', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelbase.py\", line 235, in dispatch_shell\\n    handler(stream, idents, msg)', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelbase.py\", line 399, in execute_request\\n    user_expressions, allow_stdin)', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\ipykernel\\\\ipkernel.py\", line 196, in do_execute\\n    res = shell.run_cell(code, store_history=store_history, silent=silent)', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\ipykernel\\\\zmqshell.py\", line 533, in run_cell\\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\IPython\\\\core\\\\interactiveshell.py\", line 2717, in run_cell\\n    interactivity=interactivity, compiler=compiler, result=result)', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\IPython\\\\core\\\\interactiveshell.py\", line 2821, in run_ast_nodes\\n    if self.run_code(code, result):', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\IPython\\\\core\\\\interactiveshell.py\", line 2881, in run_code\\n    exec(code_obj, self.user_global_ns, self.user_ns)', 'File \"<ipython-input-38-cbbb0c9eab03>\", line 3, in <module>\\n    y_pred = dnn_clf.predict(X_test)', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\tensorflow\\\\contrib\\\\learn\\\\python\\\\learn\\\\estimators\\\\estimator.py\", line 1383, in predict\\n    iterate_batches=True))', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\tensorflow\\\\contrib\\\\learn\\\\python\\\\learn\\\\estimators\\\\estimator.py\", line 893, in _infer_model\\n    config=self._session_config))', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\training\\\\monitored_session.py\", line 668, in __init__\\n    stop_grace_period_secs=stop_grace_period_secs)', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\training\\\\monitored_session.py\", line 490, in __init__\\n    self._sess = _RecoverableSession(self._coordinated_creator)', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\training\\\\monitored_session.py\", line 842, in __init__\\n    _WrappedSession.__init__(self, self._create_session())', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\training\\\\monitored_session.py\", line 847, in _create_session\\n    return self._sess_creator.create_session()', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\training\\\\monitored_session.py\", line 551, in create_session\\n    self.tf_sess = self._session_creator.create_session()', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\training\\\\monitored_session.py\", line 416, in create_session\\n    self._scaffold.finalize()', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\training\\\\monitored_session.py\", line 196, in finalize\\n    default_ready_for_local_init_op)', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\training\\\\monitored_session.py\", line 258, in get_or_default\\n    op = default_constructor()', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\training\\\\monitored_session.py\", line 193, in default_ready_for_local_init_op\\n    variables.global_variables())', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\util\\\\tf_should_use.py\", line 175, in wrapped\\n    return _add_should_use_warning(fn(*args, **kwargs))', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\util\\\\tf_should_use.py\", line 144, in _add_should_use_warning\\n    wrapped = TFShouldUseWarningWrapper(x)', 'File \"D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\util\\\\tf_should_use.py\", line 101, in __init__\\n    stack = [s.strip() for s in traceback.format_stack()]']\n",
      "==================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Akira\\AppData\\Local\\Temp\\tmp5jmjqb78\\model.ckpt-3500\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "tensor_name = dnn/hiddenlayer_0/weights; shape in shape_and_slice spec [10000,2000] does not match the shape stored in checkpoint: [49000,2000]\n\t [[Node: save/RestoreV2_1 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_save/Const_0_0, save/RestoreV2_1/tensor_names, save/RestoreV2_1/shape_and_slices)]]\n\nCaused by op 'save/RestoreV2_1', defined at:\n  File \"D:\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"D:\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"D:\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"D:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"D:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"D:\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"D:\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"D:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"D:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"D:\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"D:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"D:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"D:\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"D:\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"D:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"D:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"D:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-48-1a86901d1f36>\", line 3, in <module>\n    y_pred = dnn_clf.predict(X_test)\n  File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\", line 1383, in predict\n    iterate_batches=True))\n  File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\", line 893, in _infer_model\n    config=self._session_config))\n  File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 668, in __init__\n    stop_grace_period_secs=stop_grace_period_secs)\n  File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 490, in __init__\n    self._sess = _RecoverableSession(self._coordinated_creator)\n  File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 842, in __init__\n    _WrappedSession.__init__(self, self._create_session())\n  File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 847, in _create_session\n    return self._sess_creator.create_session()\n  File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 551, in create_session\n    self.tf_sess = self._session_creator.create_session()\n  File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 416, in create_session\n    self._scaffold.finalize()\n  File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 207, in finalize\n    self._saver = training_saver._get_saver_or_default()  # pylint: disable=protected-access\n  File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 733, in _get_saver_or_default\n    saver = Saver(sharded=True, allow_empty=True)\n  File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1140, in __init__\n    self.build()\n  File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1172, in build\n    filename=self._filename)\n  File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 684, in build\n    restore_sequentially, reshape)\n  File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 450, in _AddShardedRestoreOps\n    name=\"restore_shard\"))\n  File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 407, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 247, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 663, in restore_v2\n    dtypes=dtypes, name=name)\n  File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): tensor_name = dnn/hiddenlayer_0/weights; shape in shape_and_slice spec [10000,2000] does not match the shape stored in checkpoint: [49000,2000]\n\t [[Node: save/RestoreV2_1 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_save/Const_0_0, save/RestoreV2_1/tensor_names, save/RestoreV2_1/shape_and_slices)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1306\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[1;34m()\u001b[0m\n\u001b[0;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[0;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: tensor_name = dnn/hiddenlayer_0/weights; shape in shape_and_slice spec [10000,2000] does not match the shape stored in checkpoint: [49000,2000]\n\t [[Node: save/RestoreV2_1 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_save/Const_0_0, save/RestoreV2_1/tensor_names, save/RestoreV2_1/shape_and_slices)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-1a86901d1f36>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdnn_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'classes'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'classes'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3073\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'classes'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, outputs)\u001b[0m\n\u001b[0;32m   1381\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1382\u001b[0m             \u001b[0mas_iterable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1383\u001b[1;33m             iterate_batches=True))\n\u001b[0m\u001b[0;32m   1384\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1385\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moutput\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\u001b[0m in \u001b[0;36m_infer_model\u001b[1;34m(self, input_fn, feed_fn, outputs, as_iterable, iterate_batches)\u001b[0m\n\u001b[0;32m    891\u001b[0m               \u001b[0mcheckpoint_filename_with_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    892\u001b[0m               \u001b[0mscaffold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minfer_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscaffold\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 893\u001b[1;33m               config=self._session_config))\n\u001b[0m\u001b[0;32m    894\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mas_iterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    895\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, session_creator, hooks, stop_grace_period_secs)\u001b[0m\n\u001b[0;32m    666\u001b[0m     super(MonitoredSession, self).__init__(\n\u001b[0;32m    667\u001b[0m         \u001b[0msession_creator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshould_recover\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m         stop_grace_period_secs=stop_grace_period_secs)\n\u001b[0m\u001b[0;32m    669\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, session_creator, hooks, should_recover, stop_grace_period_secs)\u001b[0m\n\u001b[0;32m    488\u001b[0m         stop_grace_period_secs=stop_grace_period_secs)\n\u001b[0;32m    489\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshould_recover\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 490\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_RecoverableSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_coordinated_creator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    491\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_coordinated_creator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, sess_creator)\u001b[0m\n\u001b[0;32m    840\u001b[0m     \"\"\"\n\u001b[0;32m    841\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess_creator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess_creator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 842\u001b[1;33m     \u001b[0m_WrappedSession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    843\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    844\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_create_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36m_create_session\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    845\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 847\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess_creator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    848\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m         logging.info('An error was raised while a session was being created. '\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mcreate_session\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    549\u001b[0m       \u001b[1;34m\"\"\"Creates a coordinated session.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m       \u001b[1;31m# Keep the tf_sess for unit testing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_sess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session_creator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m       \u001b[1;31m# We don't want coordinator to suppress any exception.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoord\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcoordinator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCoordinator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean_stop_exception_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mcreate_session\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[0minit_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_scaffold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m         \u001b[0minit_feed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_scaffold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_feed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m         init_fn=self._scaffold.init_fn)\n\u001b[0m\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\session_manager.py\u001b[0m in \u001b[0;36mprepare_session\u001b[1;34m(self, master, init_op, saver, checkpoint_dir, checkpoint_filename_with_path, wait_for_checkpoint, max_wait_secs, config, init_feed_dict, init_fn)\u001b[0m\n\u001b[0;32m    271\u001b[0m         \u001b[0mwait_for_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwait_for_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m         \u001b[0mmax_wait_secs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_wait_secs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 273\u001b[1;33m         config=config)\n\u001b[0m\u001b[0;32m    274\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_loaded_from_checkpoint\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0minit_op\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0minit_fn\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_local_init_op\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\session_manager.py\u001b[0m in \u001b[0;36m_restore_checkpoint\u001b[1;34m(self, master, saver, checkpoint_dir, checkpoint_filename_with_path, wait_for_checkpoint, max_wait_secs, config)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcheckpoint_filename_with_path\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m       \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpoint_filename_with_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1558\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Restoring parameters from %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1559\u001b[0m     sess.run(self.saver_def.restore_op_name,\n\u001b[1;32m-> 1560\u001b[1;33m              {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[0;32m   1561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1562\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1122\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1124\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1125\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1321\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1338\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1339\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1340\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1342\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: tensor_name = dnn/hiddenlayer_0/weights; shape in shape_and_slice spec [10000,2000] does not match the shape stored in checkpoint: [49000,2000]\n\t [[Node: save/RestoreV2_1 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_save/Const_0_0, save/RestoreV2_1/tensor_names, save/RestoreV2_1/shape_and_slices)]]\n\nCaused by op 'save/RestoreV2_1', defined at:\n  File \"D:\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"D:\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"D:\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"D:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"D:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"D:\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"D:\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"D:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"D:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"D:\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"D:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"D:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"D:\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"D:\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"D:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"D:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"D:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-48-1a86901d1f36>\", line 3, in <module>\n    y_pred = dnn_clf.predict(X_test)\n  File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\", line 1383, in predict\n    iterate_batches=True))\n  File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\", line 893, in _infer_model\n    config=self._session_config))\n  File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 668, in __init__\n    stop_grace_period_secs=stop_grace_period_secs)\n  File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 490, in __init__\n    self._sess = _RecoverableSession(self._coordinated_creator)\n  File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 842, in __init__\n    _WrappedSession.__init__(self, self._create_session())\n  File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 847, in _create_session\n    return self._sess_creator.create_session()\n  File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 551, in create_session\n    self.tf_sess = self._session_creator.create_session()\n  File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 416, in create_session\n    self._scaffold.finalize()\n  File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 207, in finalize\n    self._saver = training_saver._get_saver_or_default()  # pylint: disable=protected-access\n  File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 733, in _get_saver_or_default\n    saver = Saver(sharded=True, allow_empty=True)\n  File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1140, in __init__\n    self.build()\n  File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1172, in build\n    filename=self._filename)\n  File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 684, in build\n    restore_sequentially, reshape)\n  File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 450, in _AddShardedRestoreOps\n    name=\"restore_shard\"))\n  File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 407, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 247, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 663, in restore_v2\n    dtypes=dtypes, name=name)\n  File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): tensor_name = dnn/hiddenlayer_0/weights; shape in shape_and_slice spec [10000,2000] does not match the shape stored in checkpoint: [49000,2000]\n\t [[Node: save/RestoreV2_1 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_save/Const_0_0, save/RestoreV2_1/tensor_names, save/RestoreV2_1/shape_and_slices)]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = dnn_clf.predict(X_test)\n",
    "y_pred['classes'] = y_pred['classes'].shape(3073,1)\n",
    "accuracy_score(y_test, y_pred['classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "y_pred_proba = y_pred['probabilities']\n",
    "log_loss(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
