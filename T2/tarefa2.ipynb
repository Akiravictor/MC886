{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Instructions\n",
    "* One vs all logistic regression\n",
    "* Softmax regression = generalization to handle multiple classes\n",
    "* Neural network with one hidden layer, and numerically checking the gradient\n",
    "* Now 2 hidden layers and different activation f'ns, see what performs best\n",
    "* With best model, do confusion matrix on test set\n",
    "* 4 page report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# notebook setup\n",
    "import random \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Importing the data\n",
    "\n",
    "We have 50 000 32x32 images in the train set and a \"labels\" file with 50 000 lines.\n",
    "\n",
    "For the images, we'll store them as a 50000x3072 np array, so the first 1024 columns are the value of the red pixel in the image of that row, and the next two 1024 columns are the green and blue values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "def get_data(cifar_dirname=\"/home/zoug/Cours/MC886/tarefa2/cifar-10/train/\"):    \n",
    "    classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "    X = np.empty(shape=(1,3072))\n",
    "    # we load the 50 000 images in X one after the other, one image being 1x3072, to obtain the 50000x3072 array\n",
    "    for i in range(50000):\n",
    "        # to have an update of where we're at once in a while\n",
    "        if i % 1000 == 0:\n",
    "            print(i)\n",
    "        # open the current image\n",
    "        current_im  = Image.open(cifar_dirname + str(i).zfill(5) + \".png\" )\n",
    "        # reshape it into an (1,3072) array, so the red values of all the pixels, then green then blue (32*32*3)\n",
    "        reshaped_im = np.reshape(np.asarray(current_im, 'uint8'), (1,3072))\n",
    "        # vertical stack the image into X, what will contain all the images\n",
    "        X           = np.vstack([X, reshaped_im])\n",
    "        \n",
    "    # we want the array to be of type unsigned int on 8 bit (between 0 and 255), so that it occupies the minimum space\n",
    "    X = X.astype(\"uint8\")\n",
    "    # we load the 50 000 labels for the txt file\n",
    "    y = np.loadtxt(cifar_dirname+\"labels\")\n",
    "    return X, y\n",
    "\n",
    "X, y = get_data()\n",
    "X.shape\n",
    "y.shape\n",
    "\n",
    "# since loading the images took a lot of time (~3hr), we'll save them in a binary file (.npy)\n",
    "np.save(\"/home/zoug/Cours/MC886/tarefa2/cifar-10/train/images\", X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now to get the nparray back\n",
    "X = np.load(\"/home/zoug/Cours/MC886/tarefa2/cifar-10/train/images.npy\")\n",
    "# also, for the y array, like earlier:\n",
    "y = np.loadtxt(\"/home/zoug/Cours/MC886/tarefa2/cifar-10/train/labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Preprocessing the data\n",
    "\n",
    "We need to do feature scaling on the images before feeding them into the algorithms. We first get the values between -1 and 1: since they're all between 0 and 255, we'll divide by 127 and substract 1.\n",
    "\n",
    "We then calculate the mean of each image and substract each row by that value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-3d71148b8dcb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# we'll then transpose it back to 50000,3072\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-3d71148b8dcb>\u001b[0m in \u001b[0;36mpreprocessing_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocessing_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# get values between -1 and 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdivide\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m127\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"float64\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def preprocessing_data(data):\n",
    "    # get values between -1 and 1\n",
    "    data = np.divide(data, 127).astype(\"float64\")\n",
    "    data -= 1\n",
    "    \n",
    "    # calculate the mean of each image\n",
    "    mean = np.mean(data, axis=1) # shape (50000,)\n",
    "    data = (data.transpose() - mean) # substract each row by corresponding mean\n",
    "    # note that data is now transposed, shape (3072, 50000)\n",
    "    \n",
    "    # apply the PCA algorithm\n",
    "    #pca = PCA(n_components=3072)\n",
    "    #data = pca.fit_transform(data)\n",
    "    #print(data.shape)\n",
    "    return data.transpose() # we'll then transpose it back to 50000,3072\n",
    "\n",
    "X = preprocessing_data(X)\n",
    "X[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "X_scaled.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then try to reduce the number of feutres by projecting on a principal subspace, with the PCA algorithm. To do so we first run it on the data, then print the variances and decide the number of features we want to keep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# basic standardization (PCA does that already)\n",
    "X = np.divide(X, 127).astype(\"float64\")\n",
    "X -= 1\n",
    "pca = PCA()\n",
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< e^-10: 0\n",
      "< e^-9: 0\n",
      "< e^-8: 0\n",
      "< e^-7: 0\n",
      "< e^-6: 0\n",
      "< e^-5: 36\n",
      "< e^-4: 583\n",
      "< e^-3: 1364\n",
      "< e^-2: 2140\n",
      "< e^-1: 2758\n",
      "< e^0: 3006\n",
      "< e^1: 3061\n",
      "< e^2: 3071\n",
      "< e^3: 3072\n",
      "< e^4: 3072\n",
      "< e^5: 3072\n",
      "< e^6: 3072\n",
      "< e^7: 3072\n",
      "< e^8: 3072\n",
      "< e^9: 3072\n"
     ]
    }
   ],
   "source": [
    "for i in range(-10,10):\n",
    "    a = 0\n",
    "    for x in pca.explained_variance_:\n",
    "        if x < pow(10,i):\n",
    "            a = a + 1\n",
    "    print(\"< e^\"+str(i)+\": \"+str(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll try to keep 2400 features, thus disregarding the ~600 features with a covariance inferiour to 10^-4. This will already help a lot with the calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca.n_components = 2400\n",
    "X_reduced = pca.fit_transform(X)\n",
    "X_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
